{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be56cd72",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263d5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from model.mpnn import SolvationModel\n",
    "import numpy as np\n",
    "from model.custoum_dataset import SolPropDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from types import SimpleNamespace\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0a56e",
   "metadata": {},
   "source": [
    "# Fix the random state for reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff44471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ef2e3",
   "metadata": {},
   "source": [
    "# Hyperparameters (need to be optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4b2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.hidden_size = 200             # D-MPNN hidden dim # hyperparameter\n",
    "        self.ffn_hidden_size = 100         # Feedforward hidden dim # hyperparameter\n",
    "        self.output_size = 2               # # of properties\n",
    "        self.dropout = 0.1                 # dropout # hyperparameter\n",
    "        self.bias = True\n",
    "        self.depth = 2                     \n",
    "        self.activation = \"ReLU\"           # activation\n",
    "        self.cuda = True                   # GPU\n",
    "        self.property = \"solvation\"\n",
    "        self.aggregation = \"mean\"\n",
    "        self.atomMessage = False           # False: only atom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed661a",
   "metadata": {},
   "source": [
    "# Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66300ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batched_data = {\n",
    "        'solute': [item['solute'] for item in batch],                 # list of dict\n",
    "        'solvent_list': [item['solvent_list'] for item in batch],     # list of list of dict\n",
    "        'mol_frac': torch.stack([item['mol_frac'] for item in batch]),\n",
    "        'target': torch.stack([item['target'] for item in batch])     # (B, 2)\n",
    "    }\n",
    "    return batched_data\n",
    "\n",
    "def to_namespace(obj):\n",
    "    return obj if isinstance(obj, SimpleNamespace) else SimpleNamespace(**obj)\n",
    "\n",
    "# move dict tensors to device\n",
    "def move_batch_to_device(batch, device):\n",
    "    batch['mol_frac'] = batch['mol_frac'].to(device)\n",
    "    batch['target']   = batch['target'].to(device)\n",
    "\n",
    "    # Move solutes\n",
    "    solutes = []\n",
    "    for solute in batch['solute']:\n",
    "        solute_ns = to_namespace(solute)\n",
    "        for k, v in vars(solute_ns).items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                setattr(solute_ns, k, v.to(device))\n",
    "        solutes.append(solute_ns)\n",
    "    batch['solute'] = solutes\n",
    "\n",
    "    # Move solvents\n",
    "    solvents_out = []\n",
    "    for solvent_list in batch['solvent_list']:\n",
    "        tmp = []\n",
    "        for solvent in solvent_list:\n",
    "            solvent_ns = to_namespace(solvent)\n",
    "            for k, v in vars(solvent_ns).items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    setattr(solvent_ns, k, v.to(device))\n",
    "            tmp.append(solvent_ns)\n",
    "        solvents_out.append(tmp)\n",
    "    batch['solvent_list'] = solvents_out\n",
    "    return batch\n",
    "\n",
    "# metrics\n",
    "def rmse(y_hat, y):\n",
    "    return torch.sqrt(torch.mean((y_hat - y) ** 2)).item()\n",
    "def mae(y_hat, y):\n",
    "    return torch.mean(torch.abs(y_hat - y)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a0eb1",
   "metadata": {},
   "source": [
    "# Load processed dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457901b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use another data, go to 'preprocessing' folder and save it based on 'preprocessing_binary.py' file\n",
    "data_path = \"train_binary.pkl\"   \n",
    "with open(data_path, 'rb') as f:\n",
    "    data_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb711c",
   "metadata": {},
   "source": [
    "# datasplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2171f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SolPropDataset(data_list)\n",
    "train_size = int(0.8 * len(dataset)) # 0.8 -> train:test = 8:2\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9275ff",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb20d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # hyperparameter\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df6500",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ea04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "targets = []\n",
    "for item in dataset:\n",
    "    targets.append(item['target'].cpu().numpy())\n",
    "targets = np.array(targets)\n",
    "\n",
    "scaler = StandardScaler() # MinMaxScaler # hyperparameter\n",
    "scaler.fit(targets)\n",
    "# scaler save\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee96cba",
   "metadata": {},
   "source": [
    "# model/optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "device = torch.device('cuda' if (args.cuda and torch.cuda.is_available()) else 'cpu')\n",
    "model = SolvationModel(args).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3) # hyperparameter\n",
    "criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b203db",
   "metadata": {},
   "source": [
    "# model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1/100:   0%|          | 0/3 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1/100: 100%|██████████| 3/3 [00:04<00:00,  1.54s/batch, loss=1.51]\n",
      "[Val]   Epoch 1/100: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Train Loss=2.4446 RMSE=1.0871 MAE=0.7122 | Val Loss=1.5125 RMSE=1.0354 MAE=0.7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 2/100: 100%|██████████| 3/3 [00:04<00:00,  1.59s/batch, loss=1.24]\n",
      "[Val]   Epoch 2/100: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: Train Loss=2.0605 RMSE=0.9911 MAE=0.7062 | Val Loss=1.2384 RMSE=1.0513 MAE=0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3/100: 100%|██████████| 3/3 [00:04<00:00,  1.63s/batch, loss=2.1] \n",
      "[Val]   Epoch 3/100: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s, loss=2.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: Train Loss=2.1681 RMSE=1.0373 MAE=0.7579 | Val Loss=2.1004 RMSE=1.0126 MAE=0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 4/100: 100%|██████████| 3/3 [00:04<00:00,  1.59s/batch, loss=1.19]\n",
      "[Val]   Epoch 4/100: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: Train Loss=1.9202 RMSE=0.9644 MAE=0.6698 | Val Loss=1.1936 RMSE=1.0199 MAE=0.7339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 5/100: 100%|██████████| 3/3 [00:05<00:00,  1.74s/batch, loss=1.15]\n",
      "[Val]   Epoch 5/100: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004: Train Loss=1.9308 RMSE=0.9571 MAE=0.6300 | Val Loss=1.1523 RMSE=1.0249 MAE=0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 6/100: 100%|██████████| 3/3 [00:04<00:00,  1.60s/batch, loss=1.95]\n",
      "[Val]   Epoch 6/100: 100%|██████████| 1/1 [00:00<00:00,  2.03batch/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005: Train Loss=1.9085 RMSE=0.9765 MAE=0.6253 | Val Loss=1.9544 RMSE=0.9886 MAE=0.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 7/100: 100%|██████████| 3/3 [00:04<00:00,  1.63s/batch, loss=2.83]\n",
      "[Val]   Epoch 7/100: 100%|██████████| 1/1 [00:00<00:00,  1.84batch/s, loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006: Train Loss=1.7842 RMSE=0.9347 MAE=0.6291 | Val Loss=2.8290 RMSE=0.9761 MAE=0.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 8/100: 100%|██████████| 3/3 [00:05<00:00,  1.71s/batch, loss=1.85]\n",
      "[Val]   Epoch 8/100: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s, loss=1.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007: Train Loss=1.7770 RMSE=0.9354 MAE=0.6473 | Val Loss=1.8464 RMSE=0.9696 MAE=0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 9/100: 100%|██████████| 3/3 [00:04<00:00,  1.59s/batch, loss=2.18]\n",
      "[Val]   Epoch 9/100: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s, loss=2.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008: Train Loss=1.7243 RMSE=0.9282 MAE=0.6209 | Val Loss=2.1775 RMSE=0.9626 MAE=0.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 10/100: 100%|██████████| 3/3 [00:05<00:00,  1.79s/batch, loss=2.69] \n",
      "[Val]   Epoch 10/100: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s, loss=2.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009: Train Loss=1.6722 RMSE=0.8989 MAE=0.5935 | Val Loss=2.6891 RMSE=0.9586 MAE=0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 11/100: 100%|██████████| 3/3 [00:04<00:00,  1.61s/batch, loss=1.09]\n",
      "[Val]   Epoch 11/100: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010: Train Loss=1.6487 RMSE=0.8865 MAE=0.5885 | Val Loss=1.0913 RMSE=0.9539 MAE=0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 12/100: 100%|██████████| 3/3 [00:04<00:00,  1.50s/batch, loss=1.09]\n",
      "[Val]   Epoch 12/100: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011: Train Loss=1.6223 RMSE=0.8845 MAE=0.5863 | Val Loss=1.0855 RMSE=0.9567 MAE=0.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 13/100: 100%|██████████| 3/3 [00:04<00:00,  1.64s/batch, loss=1.4] \n",
      "[Val]   Epoch 13/100: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s, loss=1.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012: Train Loss=1.5954 RMSE=0.8846 MAE=0.5792 | Val Loss=1.4032 RMSE=0.9590 MAE=0.6503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 14/100: 100%|██████████| 3/3 [00:04<00:00,  1.55s/batch, loss=0.876]\n",
      "[Val]   Epoch 14/100: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s, loss=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013: Train Loss=1.5857 RMSE=0.8450 MAE=0.5876 | Val Loss=0.8755 RMSE=0.9622 MAE=0.6510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 15/100: 100%|██████████| 3/3 [00:05<00:00,  1.68s/batch, loss=1.25]\n",
      "[Val]   Epoch 15/100: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014: Train Loss=1.5169 RMSE=0.8594 MAE=0.5552 | Val Loss=1.2459 RMSE=0.9691 MAE=0.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 16/100: 100%|██████████| 3/3 [00:04<00:00,  1.54s/batch, loss=1.13]\n",
      "[Val]   Epoch 16/100: 100%|██████████| 1/1 [00:00<00:00,  1.88batch/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015: Train Loss=1.5366 RMSE=0.8583 MAE=0.5527 | Val Loss=1.1264 RMSE=0.9682 MAE=0.6482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 17/100: 100%|██████████| 3/3 [00:04<00:00,  1.57s/batch, loss=1.8]  \n",
      "[Val]   Epoch 17/100: 100%|██████████| 1/1 [00:00<00:00,  1.86batch/s, loss=1.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016: Train Loss=1.5345 RMSE=0.8654 MAE=0.5580 | Val Loss=1.8002 RMSE=0.9713 MAE=0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 18/100: 100%|██████████| 3/3 [00:04<00:00,  1.63s/batch, loss=2.29] \n",
      "[Val]   Epoch 18/100: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s, loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017: Train Loss=1.5507 RMSE=0.8738 MAE=0.5848 | Val Loss=2.2938 RMSE=0.9765 MAE=0.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 19/100: 100%|██████████| 3/3 [00:04<00:00,  1.63s/batch, loss=0.736]\n",
      "[Val]   Epoch 19/100: 100%|██████████| 1/1 [00:00<00:00,  1.65batch/s, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018: Train Loss=1.5434 RMSE=0.8271 MAE=0.5695 | Val Loss=0.7358 RMSE=0.9807 MAE=0.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 20/100: 100%|██████████| 3/3 [00:05<00:00,  1.73s/batch, loss=2.26]\n",
      "[Val]   Epoch 20/100: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s, loss=2.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019: Train Loss=1.5261 RMSE=0.8694 MAE=0.5421 | Val Loss=2.2594 RMSE=0.9881 MAE=0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 21/100: 100%|██████████| 3/3 [00:04<00:00,  1.66s/batch, loss=1.36]\n",
      "[Val]   Epoch 21/100: 100%|██████████| 1/1 [00:00<00:00,  1.65batch/s, loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020: Train Loss=1.5007 RMSE=0.8616 MAE=0.5476 | Val Loss=1.3585 RMSE=0.9877 MAE=0.6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 22/100: 100%|██████████| 3/3 [00:04<00:00,  1.59s/batch, loss=1.41] \n",
      "[Val]   Epoch 22/100: 100%|██████████| 1/1 [00:00<00:00,  1.66batch/s, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021: Train Loss=1.5194 RMSE=0.8563 MAE=0.5632 | Val Loss=1.4075 RMSE=0.9889 MAE=0.6678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 23/100: 100%|██████████| 3/3 [00:04<00:00,  1.56s/batch, loss=1.46] \n",
      "[Val]   Epoch 23/100: 100%|██████████| 1/1 [00:00<00:00,  1.66batch/s, loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022: Train Loss=1.4921 RMSE=0.8480 MAE=0.5485 | Val Loss=1.4640 RMSE=0.9925 MAE=0.6624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 24/100: 100%|██████████| 3/3 [00:04<00:00,  1.61s/batch, loss=0.924]\n",
      "[Val]   Epoch 24/100: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s, loss=0.924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023: Train Loss=1.5199 RMSE=0.8537 MAE=0.5421 | Val Loss=0.9240 RMSE=0.9926 MAE=0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 25/100: 100%|██████████| 3/3 [00:04<00:00,  1.59s/batch, loss=1.29]\n",
      "[Val]   Epoch 25/100: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024: Train Loss=1.4605 RMSE=0.8468 MAE=0.5453 | Val Loss=1.2920 RMSE=0.9904 MAE=0.6669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 26/100: 100%|██████████| 3/3 [00:05<00:00,  1.75s/batch, loss=1.87] \n",
      "[Val]   Epoch 26/100: 100%|██████████| 1/1 [00:00<00:00,  1.74batch/s, loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025: Train Loss=1.4998 RMSE=0.8586 MAE=0.5457 | Val Loss=1.8718 RMSE=0.9923 MAE=0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 27/100: 100%|██████████| 3/3 [00:04<00:00,  1.61s/batch, loss=0.92]\n",
      "[Val]   Epoch 27/100: 100%|██████████| 1/1 [00:00<00:00,  1.86batch/s, loss=0.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026: Train Loss=1.4564 RMSE=0.8378 MAE=0.5396 | Val Loss=0.9200 RMSE=0.9916 MAE=0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 28/100: 100%|██████████| 3/3 [00:05<00:00,  1.67s/batch, loss=1.15]\n",
      "[Val]   Epoch 28/100: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027: Train Loss=1.4671 RMSE=0.8442 MAE=0.5498 | Val Loss=1.1489 RMSE=0.9900 MAE=0.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 29/100: 100%|██████████| 3/3 [00:04<00:00,  1.64s/batch, loss=2.58] \n",
      "[Val]   Epoch 29/100: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s, loss=2.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028: Train Loss=1.4875 RMSE=0.8437 MAE=0.5400 | Val Loss=2.5826 RMSE=0.9906 MAE=0.6621\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "writer = SummaryWriter(log_dir='runs/solprop_test')\n",
    "# train loop \n",
    "best_val_loss = float('inf')\n",
    "patience = 10 # hyperparameter\n",
    "epochs_without_improve = 0\n",
    "max_epochs = 100 # hyperparameter\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # === Training ===\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_rmse = 0.0\n",
    "    train_mae  = 0.0\n",
    "    n_train    = 0\n",
    "\n",
    "    train_gsolv_loss = 0.0\n",
    "    train_gsolv_rmse = 0.0\n",
    "    train_gsolv_mae = 0.0\n",
    "\n",
    "    train_hsolv_loss = 0.0\n",
    "    train_hsolv_rmse = 0.0\n",
    "    train_hsolv_mae = 0.0\n",
    "    \n",
    "\n",
    "    tepoch = tqdm(train_loader, unit='batch', desc=f\"[Train] Epoch {epoch+1}/{max_epochs}\")\n",
    "    for batch in tepoch:\n",
    "        batch = move_batch_to_device(batch, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)   # (B, 2)\n",
    "        target = batch['target'].cpu().numpy()  # (B, 2)    \n",
    "        target_sc = torch.tensor(scaler.transform(target), dtype=torch.float, device=device)\n",
    "\n",
    "        loss_per_target = criterion(output, target_sc)  # (B, 2)\n",
    "        loss_Gsolv = loss_per_target[:, 0]\n",
    "        loss_Hsolv = loss_per_target[:, 1]\n",
    "        \n",
    "        loss = loss_Gsolv.mean() + loss_Hsolv.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        B = output.size(0)\n",
    "        n_train += B\n",
    "        train_loss += loss.item() * B\n",
    "        train_rmse += rmse(output.detach(), target_sc)\n",
    "        train_mae  += mae(output.detach(), target_sc)\n",
    "\n",
    "        train_gsolv_loss += loss_Gsolv.mean().item() * B\n",
    "        train_gsolv_rmse += rmse(output[:, 0].detach(), target_sc[:, 0])\n",
    "        train_gsolv_mae  += mae(output[:, 0].detach(), target_sc[:, 0])\n",
    "\n",
    "        train_hsolv_loss += loss_Hsolv.mean().item() * B\n",
    "        train_hsolv_rmse += rmse(output[:, 1].detach(), target_sc[:, 1])\n",
    "        train_hsolv_mae  += mae(output[:, 1].detach(), target_sc[:, 1])\n",
    "\n",
    "        tepoch.set_postfix(loss=loss.item(), refresh=False)\n",
    "\n",
    "    train_loss /= n_train\n",
    "    train_rmse /= len(train_loader)\n",
    "    train_mae  /= len(train_loader)\n",
    "\n",
    "    train_gsolv_loss /= n_train\n",
    "    train_gsolv_rmse /= len(train_loader)\n",
    "    train_gsolv_mae /= len(train_loader)\n",
    "\n",
    "    train_hsolv_loss /= n_train\n",
    "    train_hsolv_rmse /= len(train_loader)\n",
    "    train_hsolv_mae /= len(train_loader)\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"RMSE/train\", train_rmse, epoch)\n",
    "    writer.add_scalar(\"MAE/train\",  train_mae,  epoch)\n",
    "\n",
    "    writer.add_scalar(\"Loss_Gsolv/train\", train_gsolv_loss, epoch)\n",
    "    writer.add_scalar(\"RMSE_Gsolv/train\", train_gsolv_rmse, epoch)\n",
    "    writer.add_scalar(\"MAE_Gsolv/train\", train_gsolv_mae, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Loss_Hsolv/train\", train_hsolv_loss, epoch)\n",
    "    writer.add_scalar(\"Loss_Hsolv/train\", train_hsolv_rmse, epoch)\n",
    "    writer.add_scalar(\"Loss_Hsolv/train\", train_hsolv_mae, epoch)\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_rmse = 0.0\n",
    "    val_mae  = 0.0\n",
    "    n_val    = 0\n",
    "\n",
    "    val_gsolv_loss = 0.0\n",
    "    val_gsolv_rmse = 0.0\n",
    "    val_gsolv_mae = 0.0\n",
    "\n",
    "    val_hsolv_loss = 0.0\n",
    "    val_hsolv_rmse = 0.0\n",
    "    val_hsolv_mae = 0.0\n",
    "\n",
    "    vepoch = tqdm(val_loader, unit='batch', desc=f\"[Val]   Epoch {epoch+1}/{max_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in vepoch:\n",
    "            batch = move_batch_to_device(batch, device)\n",
    "\n",
    "            output = model(batch)\n",
    "            target = batch['target'].cpu().numpy()\n",
    "            target_sc = torch.tensor(scaler.transform(target), dtype=torch.float, device=device)\n",
    "\n",
    "            loss_Gsolv = loss_per_target[:, 0]\n",
    "            loss_Hsolv = loss_per_target[:, 1]\n",
    "            loss = loss_Gsolv.mean() + loss_Hsolv.mean()\n",
    "\n",
    "            B = output.size(0)\n",
    "            n_val += B\n",
    "            val_loss += loss.item() * B\n",
    "            val_rmse += rmse(output.detach(), target_sc)\n",
    "            val_mae  += mae(output.detach(), target_sc)\n",
    "\n",
    "            val_gsolv_loss += loss_Gsolv.mean().item() * B\n",
    "            val_gsolv_rmse += rmse(output[:, 0].detach(), target_sc[:, 0])\n",
    "            val_gsolv_mae  += mae(output[:, 0].detach(), target_sc[:, 0])\n",
    "\n",
    "            val_hsolv_loss += loss_Hsolv.mean().item() * B\n",
    "            val_hsolv_rmse += rmse(output[:, 1].detach(), target_sc[:, 1])\n",
    "            val_hsolv_mae  += mae(output[:, 1].detach(), target_sc[:, 1])\n",
    "\n",
    "            vepoch.set_postfix(loss=loss.item(), refresh=False)\n",
    "\n",
    "    val_loss /= n_val\n",
    "    val_rmse /= len(val_loader)\n",
    "    val_mae  /= len(val_loader)\n",
    "\n",
    "    val_gsolv_loss /= n_val\n",
    "    val_gsolv_rmse /= len(val_loader)\n",
    "    val_gsolv_mae /= len(val_loader)\n",
    "\n",
    "    val_hsolv_loss /= n_val\n",
    "    val_hsolv_rmse /= len(val_loader)\n",
    "    val_hsolv_mae /= len(val_loader)\n",
    "\n",
    "\n",
    "    writer.add_scalar(\"Loss/val\",  val_loss, epoch)\n",
    "    writer.add_scalar(\"RMSE/val\",  val_rmse, epoch)\n",
    "    writer.add_scalar(\"MAE/val\",   val_mae,  epoch)\n",
    "\n",
    "    writer.add_scalar(\"Loss_Gsolv/val\", val_gsolv_loss, epoch)\n",
    "    writer.add_scalar(\"RMSE_Gsolv/val\", val_gsolv_rmse, epoch)\n",
    "    writer.add_scalar(\"MAE_Gsolv/val\", val_gsolv_mae, epoch)\n",
    "\n",
    "    writer.add_scalar(\"Loss_Hsolv/val\", val_hsolv_loss, epoch)\n",
    "    writer.add_scalar(\"Loss_Hsolv/val\", val_hsolv_rmse, epoch)\n",
    "    writer.add_scalar(\"Loss_Hsolv/val\", val_hsolv_mae, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d}: \"\n",
    "          f\"Train Loss={train_loss:.4f} RMSE={train_rmse:.4f} MAE={train_mae:.4f} | \"\n",
    "          f\"Val Loss={val_loss:.4f} RMSE={val_rmse:.4f} MAE={val_mae:.4f}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_loss < best_val_loss - 1e-6:     \n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        epochs_without_improve = 0\n",
    "    else:\n",
    "        epochs_without_improve += 1\n",
    "        if epochs_without_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76243146",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cejtuto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
